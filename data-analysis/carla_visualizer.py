#!/usr/bin/env python3
"""
CARLA MTTF/MTTR Results Visualizer

This script reads results.json files generated by the CARLA MTTF/MTTR calculator
and creates comprehensive visualizations of the reliability metrics.
"""

import json
import argparse
import sys
from pathlib import Path
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
from datetime import datetime


class CarlaResultsVisualizer:
    """Visualizes MTTF and MTTR results from CARLA simulations"""
    
    def __init__(self, results_file: str):
        """
        Initialize visualizer with results file
        
        Args:
            results_file: Path to results.json file
        """
        self.results_file = results_file
        self.data = self.load_results()
        
        # Set up matplotlib style
        plt.style.use('seaborn-v0_8-darkgrid')
        self.colors = {
            'collision': '#e74c3c',      # Red
            'lane_deviation': '#f39c12',  # Orange
            'speed_violation': '#3498db', # Blue
            'mttf': '#2ecc71',            # Green
            'mttr': '#9b59b6'             # Purple
        }
    
    def load_results(self) -> Dict:
        """Load results from JSON file"""
        try:
            with open(self.results_file, 'r') as f:
                data = json.load(f)
            print(f"Loaded results for {len(data.get('runs', []))} simulation runs")
            return data
        except FileNotFoundError:
            print(f"Error: File {self.results_file} not found")
            sys.exit(1)
        except json.JSONDecodeError as e:
            print(f"Error parsing JSON: {e}")
            sys.exit(1)
    
    def plot_mttf_comparison(self, ax=None):
        """Plot MTTF comparison across all runs"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(12, 6))
        
        runs = self.data.get('runs', [])
        if not runs:
            ax.text(0.5, 0.5, 'No data available', ha='center', va='center')
            return
        
        run_names = [r['simulation_name'] for r in runs]
        mttf_values = [r['mttf_seconds'] for r in runs]
        
        bars = ax.bar(range(len(run_names)), mttf_values, color=self.colors['mttf'], alpha=0.7)
        
        # Add value labels on bars
        for i, (bar, val) in enumerate(zip(bars, mttf_values)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:.2f}s',
                   ha='center', va='bottom', fontsize=9)
        
        # Add average line
        avg_mttf = self.data.get('summary', {}).get('average_mttf_seconds', 0)
        if avg_mttf > 0:
            ax.axhline(y=avg_mttf, color='red', linestyle='--', linewidth=2, 
                      label=f'Average: {avg_mttf:.2f}s')
        
        ax.set_xlabel('Simulation Run', fontsize=12, fontweight='bold')
        ax.set_ylabel('MTTF (seconds)', fontsize=12, fontweight='bold')
        ax.set_title('Mean Time to Failure (MTTF) Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(range(len(run_names)))
        ax.set_xticklabels(run_names, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        return ax
    
    def plot_mttr_comparison(self, ax=None):
        """Plot MTTR comparison across all runs"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(12, 6))
        
        runs = self.data.get('runs', [])
        if not runs:
            ax.text(0.5, 0.5, 'No data available', ha='center', va='center')
            return
        
        run_names = [r['simulation_name'] for r in runs]
        mttr_values = [r['mttr_seconds'] if r['mttr_seconds'] > 0 else None for r in runs]
        
        # Filter out None values for plotting
        valid_indices = [i for i, v in enumerate(mttr_values) if v is not None]
        valid_names = [run_names[i] for i in valid_indices]
        valid_values = [mttr_values[i] for i in valid_indices]
        
        if not valid_values:
            ax.text(0.5, 0.5, 'No MTTR data available\n(no recoverable failures)', 
                   ha='center', va='center', fontsize=12)
            ax.set_title('Mean Time to Repair (MTTR) Comparison', fontsize=14, fontweight='bold')
            return
        
        bars = ax.bar(range(len(valid_names)), valid_values, color=self.colors['mttr'], alpha=0.7)
        
        # Add value labels on bars
        for bar, val in zip(bars, valid_values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{val:.2f}s',
                   ha='center', va='bottom', fontsize=9)
        
        # Add average line
        avg_mttr = self.data.get('summary', {}).get('average_mttr_seconds', 0)
        if avg_mttr > 0:
            ax.axhline(y=avg_mttr, color='red', linestyle='--', linewidth=2, 
                      label=f'Average: {avg_mttr:.2f}s')
        
        ax.set_xlabel('Simulation Run', fontsize=12, fontweight='bold')
        ax.set_ylabel('MTTR (seconds)', fontsize=12, fontweight='bold')
        ax.set_title('Mean Time to Repair (MTTR) Comparison', fontsize=14, fontweight='bold')
        ax.set_xticks(range(len(valid_names)))
        ax.set_xticklabels(valid_names, rotation=45, ha='right')
        if avg_mttr > 0:
            ax.legend()
        ax.grid(True, alpha=0.3)
        
        return ax
    
    def plot_failure_type_breakdown(self, ax=None):
        """Plot stacked bar chart of failure types for each run"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(12, 6))
        
        runs = self.data.get('runs', [])
        if not runs:
            ax.text(0.5, 0.5, 'No data available', ha='center', va='center')
            return
        
        run_names = [r['simulation_name'] for r in runs]
        collisions = [r['collision_count'] for r in runs]
        lane_devs = [r['lane_deviation_count'] for r in runs]
        speed_vios = [r['speed_violation_count'] for r in runs]
        
        x = np.arange(len(run_names))
        width = 0.6
        
        # Create stacked bars
        p1 = ax.bar(x, collisions, width, label='Collisions', 
                   color=self.colors['collision'], alpha=0.8)
        p2 = ax.bar(x, lane_devs, width, bottom=collisions,
                   label='Lane Deviations', color=self.colors['lane_deviation'], alpha=0.8)
        p3 = ax.bar(x, speed_vios, width, 
                   bottom=np.array(collisions) + np.array(lane_devs),
                   label='Speed Violations', color=self.colors['speed_violation'], alpha=0.8)
        
        # Add total labels on top
        totals = [c + l + s for c, l, s in zip(collisions, lane_devs, speed_vios)]
        for i, total in enumerate(totals):
            ax.text(i, total, str(total), ha='center', va='bottom', fontweight='bold')
        
        ax.set_xlabel('Simulation Run', fontsize=12, fontweight='bold')
        ax.set_ylabel('Number of Failures', fontsize=12, fontweight='bold')
        ax.set_title('Failure Type Breakdown by Run', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(run_names, rotation=45, ha='right')
        ax.legend(loc='upper left')
        ax.grid(True, alpha=0.3, axis='y')
        
        return ax
    
    def plot_failure_timeline(self, run_index: int = 0, ax=None):
        """Plot timeline of failures for a specific run"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(14, 6))
        
        runs = self.data.get('runs', [])
        if not runs or run_index >= len(runs):
            ax.text(0.5, 0.5, 'No data available for this run', ha='center', va='center')
            return
        
        run = runs[run_index]
        failures = run.get('failures', [])
        
        if not failures:
            ax.text(0.5, 0.5, 'No failures in this run', ha='center', va='center')
            return
        
        # Separate by type
        collision_times = []
        lane_dev_times = []
        speed_vio_times = []
        
        for f in failures:
            ttf = f['ttf_seconds']
            if f['type'] == 'collision':
                collision_times.append(ttf)
            elif f['type'] == 'lane_deviation':
                lane_dev_times.append(ttf)
            elif f['type'] == 'speed_violation':
                speed_vio_times.append(ttf)
        
        # Plot as scatter points at different y-levels
        y_level = {'collision': 3, 'lane_deviation': 2, 'speed_violation': 1}
        
        if collision_times:
            ax.scatter(collision_times, [y_level['collision']] * len(collision_times),
                      color=self.colors['collision'], s=100, alpha=0.7, 
                      marker='X', label='Collision', edgecolors='black', linewidths=1)
        
        if lane_dev_times:
            ax.scatter(lane_dev_times, [y_level['lane_deviation']] * len(lane_dev_times),
                      color=self.colors['lane_deviation'], s=100, alpha=0.7, 
                      marker='o', label='Lane Deviation', edgecolors='black', linewidths=1)
        
        if speed_vio_times:
            ax.scatter(speed_vio_times, [y_level['speed_violation']] * len(speed_vio_times),
                      color=self.colors['speed_violation'], s=100, alpha=0.7, 
                      marker='s', label='Speed Violation', edgecolors='black', linewidths=1)
        
        # Add recovery indicators for non-fatal failures
        for f in failures:
            if not f['is_fatal'] and f['ttr_seconds'] is not None:
                ttf = f['ttf_seconds']
                repair_time = ttf + f['ttr_seconds']
                y = y_level.get(f['type'], 1)
                # Draw line from failure to repair
                ax.plot([ttf, repair_time], [y, y], 'k--', alpha=0.3, linewidth=2)
                # Mark repair point
                ax.scatter([repair_time], [y], color='green', s=50, 
                          marker='*', zorder=5, edgecolors='black', linewidths=0.5)
        
        ax.set_xlabel('Simulation Time (seconds)', fontsize=12, fontweight='bold')
        ax.set_ylabel('Failure Type', fontsize=12, fontweight='bold')
        ax.set_yticks([1, 2, 3])
        ax.set_yticklabels(['Speed Violation', 'Lane Deviation', 'Collision'])
        ax.set_title(f'Failure Timeline: {run["simulation_name"]}', 
                    fontsize=14, fontweight='bold')
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.3, axis='x')
        
        # Add legend for recovery markers
        green_star = mpatches.Patch(color='green', label='Recovery')
        handles, labels = ax.get_legend_handles_labels()
        handles.append(green_star)
        labels.append('Recovery')
        ax.legend(handles=handles, labels=labels, loc='upper left')
        
        return ax
    
    def plot_summary_statistics(self, ax=None):
        """Plot summary statistics across all runs"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 6))
        
        summary = self.data.get('summary', {})
        
        stats = {
            'Total Runs': summary.get('total_runs', 0),
            'Avg MTTF (s)': summary.get('average_mttf_seconds', 0),
            'Avg MTTR (s)': summary.get('average_mttr_seconds', 0),
            'Total Failures': summary.get('total_failures_all_runs', 0),
            'Total Repairs': summary.get('total_repairs_all_runs', 0)
        }
        
        # Create text display
        ax.axis('off')
        
        # Title
        ax.text(0.5, 0.95, 'Summary Statistics - All Runs', 
               ha='center', va='top', fontsize=16, fontweight='bold',
               transform=ax.transAxes)
        
        # Stats table
        y_pos = 0.75
        for key, value in stats.items():
            if isinstance(value, float):
                value_str = f'{value:.3f}'
            else:
                value_str = str(value)
            
            ax.text(0.3, y_pos, f'{key}:', ha='right', va='center', 
                   fontsize=12, fontweight='bold', transform=ax.transAxes)
            ax.text(0.35, y_pos, value_str, ha='left', va='center', 
                   fontsize=12, transform=ax.transAxes)
            y_pos -= 0.12
        
        # Add box around stats
        from matplotlib.patches import FancyBboxPatch
        box = FancyBboxPatch((0.15, 0.1), 0.7, 0.75, 
                            boxstyle="round,pad=0.05",
                            edgecolor='black', facecolor='lightgray', 
                            alpha=0.2, transform=ax.transAxes)
        ax.add_patch(box)
        
        return ax
    
    def plot_mttf_mttr_scatter(self, ax=None):
        """Scatter plot of MTTF vs MTTR for each run"""
        if ax is None:
            fig, ax = plt.subplots(figsize=(10, 8))
        
        runs = self.data.get('runs', [])
        if not runs:
            ax.text(0.5, 0.5, 'No data available', ha='center', va='center')
            return
        
        mttf_values = []
        mttr_values = []
        run_names = []
        
        for run in runs:
            if run['mttr_seconds'] > 0:  # Only plot if MTTR exists
                mttf_values.append(run['mttf_seconds'])
                mttr_values.append(run['mttr_seconds'])
                run_names.append(run['simulation_name'])
        
        if not mttf_values:
            ax.text(0.5, 0.5, 'No MTTR data available for scatter plot', 
                   ha='center', va='center')
            return
        
        ax.scatter(mttf_values, mttr_values, s=200, alpha=0.6, 
                  c=range(len(mttf_values)), cmap='viridis', 
                  edgecolors='black', linewidths=2)
        
        # Annotate points
        for i, name in enumerate(run_names):
            ax.annotate(name, (mttf_values[i], mttr_values[i]), 
                       xytext=(5, 5), textcoords='offset points',
                       fontsize=9, alpha=0.8)
        
        ax.set_xlabel('MTTF (seconds)', fontsize=12, fontweight='bold')
        ax.set_ylabel('MTTR (seconds)', fontsize=12, fontweight='bold')
        ax.set_title('MTTF vs MTTR Relationship', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        return ax
    
    def create_comprehensive_report(self, output_file: str = None):
        """Create a comprehensive multi-plot report"""
        # Create figure with subplots
        fig = plt.figure(figsize=(20, 12))
        gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)
        
        # Row 1: MTTF and MTTR comparisons
        ax1 = fig.add_subplot(gs[0, :2])
        self.plot_mttf_comparison(ax1)
        
        ax2 = fig.add_subplot(gs[0, 2])
        self.plot_summary_statistics(ax2)
        
        # Row 2: Failure breakdown and MTTR
        ax3 = fig.add_subplot(gs[1, :2])
        self.plot_failure_type_breakdown(ax3)
        
        ax4 = fig.add_subplot(gs[1, 2])
        self.plot_mttr_comparison(ax4)
        
        # Row 3: Timeline and scatter
        ax5 = fig.add_subplot(gs[2, :2])
        self.plot_failure_timeline(0, ax5)
        
        ax6 = fig.add_subplot(gs[2, 2])
        self.plot_mttf_mttr_scatter(ax6)
        
        # Add overall title
        fig.suptitle('CARLA Simulation Reliability Analysis Report', 
                    fontsize=18, fontweight='bold', y=0.995)
        
        # Save or show
        if output_file:
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            print(f"\nReport saved to: {output_file}")
        else:
            plt.show()
        
        return fig
    
    def create_individual_run_reports(self, output_dir: str = 'run_reports'):
        """Create individual detailed reports for each run"""
        runs = self.data.get('runs', [])
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        for i, run in enumerate(runs):
            fig, axes = plt.subplots(2, 2, figsize=(16, 10))
            fig.suptitle(f'Detailed Report: {run["simulation_name"]}', 
                        fontsize=16, fontweight='bold')
            
            # Failure timeline
            self.plot_failure_timeline(i, axes[0, 0])
            
            # Failure type pie chart
            ax = axes[0, 1]
            types = ['Collisions', 'Lane Deviations', 'Speed Violations']
            counts = [run['collision_count'], run['lane_deviation_count'], 
                     run['speed_violation_count']]
            counts = [c for c in counts if c > 0]
            types = [t for t, c in zip(types, [run['collision_count'], 
                    run['lane_deviation_count'], run['speed_violation_count']]) if c > 0]
            
            if counts:
                colors_list = [self.colors['collision'], self.colors['lane_deviation'], 
                             self.colors['speed_violation']][:len(counts)]
                ax.pie(counts, labels=types, autopct='%1.1f%%', startangle=90,
                      colors=colors_list, explode=[0.05] * len(counts))
                ax.set_title('Failure Type Distribution')
            else:
                ax.text(0.5, 0.5, 'No failures', ha='center', va='center')
                ax.axis('off')
            
            # Key metrics
            ax = axes[1, 0]
            ax.axis('off')
            metrics = {
                'MTTF': f"{run['mttf_seconds']:.3f} seconds",
                'MTTR': f"{run['mttr_seconds']:.3f} seconds" if run['mttr_seconds'] > 0 else "N/A",
                'Total Failures': run['total_failures'],
                'Recoveries': run['total_repairs'],
                'Collisions': run['collision_count'],
                'Lane Deviations': run['lane_deviation_count'],
                'Speed Violations': run['speed_violation_count']
            }
            
            y_pos = 0.9
            ax.text(0.5, 0.95, 'Run Metrics', ha='center', va='top', 
                   fontsize=14, fontweight='bold', transform=ax.transAxes)
            
            for key, value in metrics.items():
                ax.text(0.3, y_pos, f'{key}:', ha='right', va='center',
                       fontsize=11, fontweight='bold', transform=ax.transAxes)
                ax.text(0.35, y_pos, str(value), ha='left', va='center',
                       fontsize=11, transform=ax.transAxes)
                y_pos -= 0.1
            
            # Configuration info
            ax = axes[1, 1]
            ax.axis('off')
            config = run.get('configuration', {})
            
            ax.text(0.5, 0.95, 'Configuration', ha='center', va='top',
                   fontsize=14, fontweight='bold', transform=ax.transAxes)
            
            y_pos = 0.85
            config_items = {
                'Waypoint Threshold': f"{config.get('waypoint_threshold_m', 0):.1f} m",
                'Speed Excess': f"{config.get('speed_excess_mph', 0):.1f} mph",
                'Check Interval': f"{config.get('check_interval_frames', 0)} frames"
            }
            
            for key, value in config_items.items():
                ax.text(0.3, y_pos, f'{key}:', ha='right', va='center',
                       fontsize=11, fontweight='bold', transform=ax.transAxes)
                ax.text(0.35, y_pos, value, ha='left', va='center',
                       fontsize=11, transform=ax.transAxes)
                y_pos -= 0.1
            
            plt.tight_layout()
            
            output_file = output_path / f"{run['simulation_name']}_report.png"
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            print(f"Saved report: {output_file}")
            plt.close()


def main():
    parser = argparse.ArgumentParser(
        description='Visualize CARLA MTTF/MTTR results',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s results.json
  %(prog)s results.json --output report.png
  %(prog)s results.json --individual-reports --output-dir my_reports
        """
    )
    parser.add_argument('results_file', type=str,
                       help='Path to results JSON file')
    parser.add_argument('--output', '-o', type=str, default=None,
                       help='Output file for comprehensive report (PNG)')
    parser.add_argument('--individual-reports', action='store_true',
                       help='Generate individual reports for each run')
    parser.add_argument('--output-dir', type=str, default='run_reports',
                       help='Output directory for individual reports (default: run_reports)')
    parser.add_argument('--show', action='store_true',
                       help='Display plots interactively instead of saving')
    
    args = parser.parse_args()
    
    # Validate input file
    if not Path(args.results_file).exists():
        print(f"Error: Results file '{args.results_file}' not found")
        sys.exit(1)
    
    print(f"\nLoading results from: {args.results_file}")
    
    # Create visualizer
    visualizer = CarlaResultsVisualizer(args.results_file)
    
    # Generate comprehensive report
    if args.show:
        print("\nGenerating comprehensive report...")
        visualizer.create_comprehensive_report()
    elif args.output:
        print(f"\nGenerating comprehensive report: {args.output}")
        visualizer.create_comprehensive_report(args.output)
    
    # Generate individual reports
    if args.individual_reports:
        print(f"\nGenerating individual run reports in: {args.output_dir}/")
        visualizer.create_individual_run_reports(args.output_dir)
    
    print("\nVisualization complete!")


if __name__ == '__main__':
    main()